#!/usr/bin/env python3
"""
è‡ªåŠ¨çŠ¶æ€ç”Ÿæˆå™¨ - ç›‘æ§é¡¹ç›®å˜åŒ–å¹¶æ›´æ–° status.md

åŠŸèƒ½ï¼š
1. è‡ªåŠ¨æ£€æµ‹æŠ€æœ¯æ ˆï¼ˆä» package.json, requirements.txt ç­‰ï¼‰
2. ç»Ÿè®¡é¡¹ç›®è§„æ¨¡ï¼ˆæ–‡ä»¶æ•°ã€ä»£ç è¡Œæ•°ï¼‰
3. åˆ†æç›®å½•ç»“æ„
4. ä¿ç•™ç”¨æˆ·æ‰‹åŠ¨ç¼–è¾‘çš„å†…å®¹
"""

import os
import json
import datetime
import re
import sys
from pathlib import Path
from typing import Dict, List, Tuple

# --- å¼•å…¥å…±äº«é…ç½® ---
# auto_status.py é€šå¸¸åœ¨ context/ ç›®å½•ä¸‹ï¼Œéœ€è¦å‘ä¸Šä¸€çº§å¯¼å…¥
project_root = Path(__file__).resolve().parent.parent
if str(project_root) not in sys.path:
    sys.path.insert(0, str(project_root))

try:
    from scripts.config import IGNORE_DIRS, EXTENSIONS, PROJECT_ROOT
except ImportError:
    # Fallback
    IGNORE_DIRS = {'.git', '__pycache__', 'node_modules', 'context', '.gemini', '.history'}
    EXTENSIONS = {'.py', '.md', '.json', '.js', '.vue', '.ps1', '.sh', '.txt'}
    PROJECT_ROOT = Path(__file__).resolve().parent.parent
    print("âš ï¸  Warning: Could not import scripts.config, using fallback defaults.")

# ç»Ÿè®¡ä¿¡æ¯
WARNINGS = []


def add_warning(msg: str):
    """è®°å½•è¿è¡Œä¸­çš„è­¦å‘Š"""
    WARNINGS.append(msg)
    print(f"  âš ï¸  {msg}")

# ä¾èµ–æ–‡ä»¶æ˜ å°„
DEPENDENCY_FILES = {
    'requirements.txt': 'Python',
    'Pipfile': 'Python (Pipenv)',
    'pyproject.toml': 'Python (Poetry)',
    'package.json': 'Node.js',
    'pom.xml': 'Java (Maven)',
    'build.gradle': 'Java (Gradle)',
    'Cargo.toml': 'Rust',
    'go.mod': 'Go',
    'Gemfile': 'Ruby',
    'composer.json': 'PHP',
    '*.csproj': 'C# (.NET)',
}


def detect_tech_stack(root_path: str = '.') -> Dict[str, List[str]]:
    """æ£€æµ‹é¡¹ç›®æŠ€æœ¯æ ˆ"""
    detected = {}
    
    for dep_file, tech_name in DEPENDENCY_FILES.items():
        if '*' in dep_file:
            # å¤„ç†é€šé…ç¬¦ï¼ˆå¦‚ *.csprojï¼‰
            pattern = dep_file.replace('*', '')
            for file in Path(root_path).rglob(f'*{pattern}'):
                if file.is_file():
                    detected[tech_name] = detected.get(tech_name, []) + [str(file)]
        else:
            file_path = Path(root_path) / dep_file
            if file_path.exists():
                detected[tech_name] = [str(file_path)]
    
    return detected


def extract_dependencies(tech_stack: Dict[str, List[str]]) -> Dict[str, List[str]]:
    """ä»ä¾èµ–æ–‡ä»¶ä¸­æå–ä¸»è¦ä¾èµ–"""
    dependencies = {}
    
    for tech, files in tech_stack.items():
        deps = []
        for file_path in files:
            if 'package.json' in file_path:
                try:
                    with open(file_path, 'r', encoding='utf-8') as f:
                        data = json.load(f)
                        all_deps = {**data.get('dependencies', {}), **data.get('devDependencies', {})}
                        deps = list(all_deps.keys())[:5]
                except (json.JSONDecodeError, PermissionError) as e:
                    add_warning(f"æ— æ³•è¯»å– package.json ({file_path}): {e}")
                except Exception as e:
                    add_warning(f"è§£æ package.json æ—¶å‡ºé”™: {e}")
            elif 'requirements.txt' in file_path:
                try:
                    with open(file_path, 'r', encoding='utf-8') as f:
                        lines = [line.split('==')[0].split('>=')[0].strip() 
                                for line in f if line.strip() and not line.startswith('#')]
                        deps = lines[:5]
                except Exception as e:
                    add_warning(f"è¯»å– requirements.txt ({file_path}) æ—¶å‡ºé”™: {e}")
        
        if deps:
            dependencies[tech] = deps
    
    return dependencies


def get_project_analysis(root_path: str = '.', max_depth: int = 2) -> Tuple[int, int, str]:
    """å•æ¬¡éå†é¡¹ç›®ï¼Œè·å–æ–‡ä»¶æ•°ã€è¡Œæ•°å’Œç›®å½•ç»“æ„"""
    file_count = 0
    line_count = 0
    structure = []
    
    for root, dirs, files in os.walk(root_path):
        # è®¡ç®—å½“å‰æ·±åº¦
        rel_root = os.path.relpath(root, root_path)
        level = 0 if rel_root == '.' else rel_root.count(os.sep) + 1
        
        # è¿‡æ»¤å¿½ç•¥ç›®å½•
        dirs[:] = [d for d in dirs if d not in IGNORE_DIRS]
        
        # 1. ç»Ÿè®¡æ–‡ä»¶å’Œè¡Œæ•°
        matched_files = [f for f in files if any(f.endswith(ext) for ext in EXTENSIONS)]
        for file in matched_files:
            file_count += 1
            file_path = os.path.join(root, file)
            try:
                with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                    line_count += sum(1 for line in f if line.strip())
            except (PermissionError, OSError) as e:
                add_warning(f"æ— æ³•è¯»å–æ–‡ä»¶ {file_path}: {e}")
            except Exception as e:
                add_warning(f"ç»Ÿè®¡æ–‡ä»¶ {file_path} è¡Œæ•°æ—¶å‡ºé”™: {e}")

        # 2. ç”Ÿæˆç›®å½•ç»“æ„ï¼ˆé™åˆ¶æ·±åº¦ï¼‰
        if level < max_depth:
            indent = '  ' * level
            structure.append(f"{indent}- {os.path.basename(root) if rel_root != '.' else 'ROOT'}/")
            for file in matched_files[:5]:
                structure.append(f"{indent}  - {file}")
            if len(matched_files) > 5:
                structure.append(f"{indent}  - ... ({len(matched_files)-5} more files)")
    
    return file_count, line_count, '\n'.join(structure)


def read_manual_section(status_file: str) -> str:
    """è¯»å– status.md ä¸­ç”¨æˆ·æ‰‹åŠ¨ç»´æŠ¤çš„éƒ¨åˆ†ï¼ˆä½¿ç”¨æ­£åˆ™åŒ¹é…ï¼‰"""
    default_manual = """### å½“å‰å¼€å‘ç„¦ç‚¹
_è¯·åœ¨æ­¤å¤„è®°å½•å½“å‰æ­£åœ¨è¿›è¡Œçš„å·¥ä½œ_

### å·²çŸ¥é—®é¢˜
_å¯é€‰ï¼šè®°å½•å½“å‰å·²çŸ¥ä½†æœªä¿®å¤çš„é—®é¢˜_

### ä¸‹ä¸€æ­¥è®¡åˆ’
_å¯é€‰ï¼šè®°å½•å³å°†è¿›è¡Œçš„å¼€å‘ä»»åŠ¡_"""

    if not os.path.exists(status_file):
        return default_manual
    
    try:
        with open(status_file, 'r', encoding='utf-8') as f:
            content = f.read()
            # ä½¿ç”¨æ­£åˆ™åŒ¹é… ## âœï¸ æ‰‹åŠ¨ç»´æŠ¤åŒºåŸŸ åˆ° ä¸‹ä¸€ä¸ª --- ä¹‹é—´çš„å†…å®¹
            pattern = r'## âœï¸ æ‰‹åŠ¨ç»´æŠ¤åŒºåŸŸ\s*(.*?)\s*(?=\n---|$)'
            match = re.search(pattern, content, re.DOTALL)
            if match:
                manual_content = match.group(1).strip()
                # é¢å¤–ä¿æŠ¤ï¼šå¦‚æœåŒ¹é…åˆ°äº†è‡ªåŠ¨æ›´æ–°æç¤ºï¼Œåˆ™æˆªæ–­
                if '## ğŸ”„ æ›´æ–°æ­¤æ–‡ä»¶' in manual_content:
                    manual_content = manual_content.split('## ğŸ”„ æ›´æ–°æ­¤æ–‡ä»¶')[0].strip()
                return manual_content if manual_content else default_manual
    except Exception as e:
        add_warning(f"è¯»å–æ‰‹åŠ¨åŒºåŸŸæ—¶å‡ºé”™: {e}")
    
    return default_manual


def generate_status_md(root_path: str, file_count: int, line_count: int, dir_structure: str) -> str:
    """Generate status.md content (AI-friendly English format)"""
    # 1. Detect tech stack
    tech_stack = detect_tech_stack(root_path)
    dependencies = extract_dependencies(tech_stack)
    
    # 2. Read manual section
    manual_section = read_manual_section(os.path.join(root_path, 'context', 'status.md'))
    
    # 3. Current timestamp
    current_time = datetime.datetime.now().strftime("%Y-%m-%d %H:%M")
    
    # 4. Build Markdown
    tech_stack_md = ""
    if tech_stack:
        for tech, files in tech_stack.items():
            tech_stack_md += f"- **{tech}**"
            if tech in dependencies and dependencies[tech]:
                deps_str = ', '.join(dependencies[tech])
                tech_stack_md += f" (Main Deps: {deps_str})"
            tech_stack_md += f"\n  - Detected from: `{os.path.basename(files[0])}`\n"
    else:
        tech_stack_md = "_No standard dependency files detected_"
    
    content = f"""# Project Status Snapshot (AI-Centric)

> **NOTE**: This file is automatically maintained by `context/auto_status.py`.
> DO NOT manually edit the "Auto-Generated" section.

---

## ğŸ“Š Auto-Generated Section

**Last Updated**: {current_time}  
**Project Scale**: {file_count} files, {line_count:,} lines of code

### Technology Stack
{tech_stack_md}

### Project Structure (Max Depth: 2)
```
{dir_structure}
```

---

## âœï¸ Manual Maintenance Section

{manual_section}

---

## ğŸ”„ Refresh Status

Run the following command to refresh this file:

```bash
python context/auto_status.py
```
"""
    return content


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ”„ æ­£åœ¨åˆ†æé¡¹ç›®çŠ¶æ€...")
    
    # åˆ‡æ¢åˆ°é¡¹ç›®æ ¹ç›®å½• (ç»Ÿä¸€ä½¿ç”¨ PROJECT_ROOT)
    os.chdir(PROJECT_ROOT)
    
    # å•æ¬¡éå†å®Œæˆæ‰€æœ‰ç»Ÿè®¡
    file_count, line_count, dir_structure = get_project_analysis('.')
    
    # ç”Ÿæˆå†…å®¹
    content = generate_status_md('.', file_count, line_count, dir_structure)
    
    # å†™å…¥æ–‡ä»¶
    output_file = 'context/status.md'
    try:
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write(content)
        print(f"âœ… çŠ¶æ€æ–‡ä»¶å·²æ›´æ–°: {output_file}")
    except Exception as e:
        print(f"âŒ å†™å…¥çŠ¶æ€æ–‡ä»¶å¤±è´¥: {e}")
        return

    # è¾“å‡ºè¿è¡ŒæŠ¥å‘Š
    print("\nğŸ“‹ è¿è¡ŒæŠ¥å‘Š:")
    print(f"  - æ–‡ä»¶æ•°: {file_count}")
    print(f"  - ä»£ç è¡Œæ•°: {line_count:,}")
    
    if WARNINGS:
        print(f"\nâš ï¸  å‘ç° {len(WARNINGS)} ä¸ªè­¦å‘Š:")
        for warn in WARNINGS[:5]:
            print(f"  - {warn}")
        if len(WARNINGS) > 5:
            print(f"  - ... åŠå…¶ä»– {len(WARNINGS)-5} ä¸ªè­¦å‘Š")
    else:
        print("\nâœ¨ è¿è¡ŒæˆåŠŸï¼Œæœªå‘ç°é€»è¾‘è­¦å‘Šã€‚")


if __name__ == '__main__':
    main()
